#!/usr/bin/env python3
"""
Qing Li, 20180307
"""
import sys
import argparse
import datetime
import numpy as np
from netCDF4 import Dataset
from gotmtool import nctime_to_datetime, nctime_indices, write_ts, write_pfl, get_value_lat_lon, get_index_lat_lon_nearest
from scipy.interpolate import griddata

def main():
    # process the input arguments
    parser = argparse.ArgumentParser(description="""
            Read a netCDF file containing the global surface fluxes data and
            output timeseries of variables at a given location (latitude and
            longitude) in a text file in the GOTM input file format.
            Currently support CESM surface flux data.""")
    parser.add_argument('-i', '--input', action='store', dest='fname_in',
            metavar='NCFILENAME', required=True, help='Input netCDF filename')
    parser.add_argument('-v', '--variable', action='store', dest='vname_in',
            metavar='VARNAME', required=True, nargs='+',
            help='Variable name in netCDF file, support multiple variables')
    parser.add_argument('-o', '--output', action='store', dest='fname_out',
            metavar='DATFILENAME', required=True, help='Output filename')
    parser.add_argument('-lat', '--latitude', action='store', dest='lat',
            metavar='LATITUDE', required=True,
            help='Latitude of the requested location (-90, 90)')
    parser.add_argument('-lon', '--longitude', action='store', dest='lon',
            metavar='LONGITUDE', required=True,
            help='Longitude of the requested location (0, 360)')
    parser.add_argument('-ds', '--date_start', action='store', dest='date_start',
            metavar='STARTDATE', required=True,
            help='Starting date of input data, in the format of YYYYMMDD')
    parser.add_argument('-de', '--date_end', action='store', dest='date_end',
            metavar='ENDDATE', required=True,
            help='Ending date of input data, in the format of YYYYMMDD')
    parser.add_argument('-maxd', '--max_depth', action='store', dest='max_depth',
            metavar='MAXDEPTH', required=False,
            help='Max depth of the profile data')
    parser.add_argument('-ignore_year', '--ignore_year', action='store_true',
            dest='ignore_year', required=False,
            help='''Ignore year when matching the time. Useful if the input data
            does not correspond to a particular year.''')
    parser.add_argument('--version', action='version', version='%(prog)s: 1.0')
    # parsing arguments and save to args
    args=parser.parse_args()

    # flag for testing
    l_test = False

    # flag for ignoring year
    l_ignore_year = args.ignore_year

    # print out some message
    print('Converting {} to {}...'.format(args.fname_in, args.fname_out))

    # read netCDF file
    infile = Dataset(args.fname_in, 'r')
    varlist = infile.variables.keys()
    attlist = infile.ncattrs()

    # read latitude and longitude
    for vlat in ['lat', 'LAT', 'TLAT', 'latitude', 'LATITUDE']:
        if vlat in varlist:
            lat = infile.variables[vlat][:]
            break

    for vlon in ['lon', 'LON', 'TLON', 'TLONG', 'longitude', 'LONGITUDE']:
        if vlon in varlist:
            lon = infile.variables[vlon][:]
            break

    if lat.ndim == 1 and lon.ndim == 1:
        lon2d, lat2d = np.meshgrid(lon, lat)
    elif lat.ndim == 2 and lon.ndim == 2:
        lat2d = lat
        lon2d = lon
    else:
        print('''Inconsistent dimensions of latitude (nlat = {}) and longitude
                (nlon = {}). Stop.'''.format(lat.ndim, lon.ndim))

    # check if valid sea point
    if 'REGION_MASK' in varlist:
        region_mask = infile.variables['REGION_MASK'][:]
        point_mask = get_value_lat_lon(region_mask, lat2d, lon2d, args.lat, args.lon)
        if point_mask <= 0 or point_mask >=10:
            print('Not valid sea point. Stop.')
            sys.exit(2)

    # read time dimension
    if 'time' in varlist:
        nctime = infile.variables['time']
    elif 'TIME' in varlist:
        nctime = infile.variables['TIME']
    else:
        print('Time dimension is required and should have the name \"time\" or \"TIME\"')
        sys.exit(1)

    # get time
    if l_ignore_year:
        # ignore year when matching the time
        dttime_ref = nctime_to_datetime(nctime, tidx_start=0, tidx_end=1)
        # Note: the method .replace() is required as no zero-padding is used in
        #  netcdftime.DatetimeNoLeap.strftime('%Y')...
        year_ref = dttime_ref[0].strftime('%Y').replace(' ','0')
        date_start_ref = year_ref+args.date_start[4:8]
        date_end_ref = year_ref+args.date_end[4:8]
        # get starting and ending indices
        tidx_start, tidx_end = nctime_indices(nctime, date_start_ref, date_end_ref)
        # time in datetime format
        dttime = nctime_to_datetime(nctime, tidx_start=tidx_start, tidx_end=tidx_end+1)
        # correct the year
        year_offset = int(args.date_start[0:4])-int(year_ref)
        tdat = dttime + datetime.timedelta(days=365*year_offset)
    else:
        # get starting and ending indices
        tidx_start, tidx_end = nctime_indices(nctime, args.date_start, args.date_end)
        # time in datetime format
        tdat = nctime_to_datetime(nctime, tidx_start=tidx_start, tidx_end=tidx_end+1)

    # --------
    # TEST
    if l_test:
        lat_req = args.lat
        lon_req = args.lon
        ilat, ilon = get_index_lat_lon_nearest(lat2d, lon2d, lat_req, lon_req)
        dat = ncread(infile, args.vname_in[0], tidxstart=0, tidxend=11)
        lat_int = get_value_lat_lon(lat2d, lat2d, lon2d, lat_req, lon_req)
        lon_int = get_value_lat_lon(lon2d, lat2d, lon2d, lat_req, lon_req)
        dat_int = get_value_lat_lon(dat, lat2d, lon2d, lat_req, lon_req)
        print('Requested coordinates')
        print('    lat = {}'.format(lat_req))
        print('    lon = {}'.format(lon_req))
        print('Interpolated coordinates')
        print('    lat = {}'.format(lat_int))
        print('    lon = {}'.format(lon_int))
        print('Original Data')
        print(np.asarray(dat[:,ilat,ilon]))
        print('Interpolated Data')
        print(dat_int[:,0])
        sys.exit(1)
    # --------

    # get global missing value
    if 'missing_value' in attlist:
        gmvalue = infile.missing_value
    elif '_FillValue' in attlist:
        gmvalue = infile._FillValue
    else:
        # turn off auto mask, handled in write_pfl()
        infile.set_auto_mask(False)
        gmvalue = np.nan

    # get depth
    if 'depth' in varlist:
        ddat = infile.variables['depth'][:]
        l_depth = True
    elif 'DEPTH' in varlist:
        ddat = infile.variables['DEPTH'][:]
        l_depth = True
    elif 'z_t' in varlist:
        ddat = infile.variables['z_t'][:]
        l_depth = True
    else:
        ddat = np.asarray(0.0)
        l_depth = False

    nd = ddat.size
    ddat = -abs(ddat)
    # a limit on the depth
    if l_depth:
        if args.max_depth:
            max_d = abs(float(args.max_depth))
            zidxend = np.argmin(abs(ddat+max_d))+1
            ddat = ddat[0:zidxend]
        else:
            zidxend = nd

    # output
    vdat = []    # a list of arrays, an array for each variable
    if nd == 1:
        # timeseries of surface fluxes
        for vname in args.vname_in:
            dat = ncread(infile, vname, tidxstart=tidx_start, tidxend=tidx_end+1)
            dat_int = get_value_lat_lon(dat, lat2d, lon2d, args.lat, args.lon)
            vdat.append(dat_int[:,0])
        # write to output file
        write_ts(args.fname_out, tdat, vdat, mask=gmvalue)
    else:
        # timeseries of profiles
        for vname in args.vname_in:
            dat = ncread(infile, vname, zidxend=zidxend, tidxstart=tidx_start, tidxend=tidx_end+1)
            dat_int = get_value_lat_lon(dat, lat2d, lon2d, args.lat, args.lon)
            vdat.append(dat_int[:,:,0])
        # write to output file
        write_pfl(args.fname_out, tdat, ddat, vdat, mask=gmvalue)

def ncread(infile, *argv, xidx=None, yidx=None, zidxend=None, tidxstart=0, tidxend=None):
    """Read variables from a netCDF file.

    :infile: (netCDF4 Dateset) input netCDF file
    :*argv: (str) name of variables to read
    :xidx: (int) x indices
    :yidx: (int) y indices
    :tidxstart: (int) start time index
    :tidxend: (int) end time index
    :returns: (list) value or netCDF object of requested variable

    """
    rdat = []
    for vname in argv:
        dat = infile.variables[vname]
        nsize = dat.ndim
        if nsize == 2:
            odat = dat[:]
        elif nsize == 3:
            if xidx is None or yidx is None:
                odat = dat[tidxstart:tidxend, :, :]
            else:
                odat = np.squeeze(dat[tidxstart:tidxend, yidx, xidx])
        elif nsize == 4:
            if xidx is None or yidx is None:
                odat = dat[tidxstart:tidxend, 0:zidxend, :, :]
            else:
                odat = np.squeeze(dat[tidxstart:tidxend, 0:zidxend, yidx, xidx])
        else:
            print('The variable {} has {} dimensions, not supported'
                    .format(vname, nsize))
            sys.exit(1)
        # append to var list
        # rdat.append(np.squeeze(odat))
        rdat.append(odat)

    # return a list of arrays if more than one variable are requested
    if len(rdat) == 1:
        return rdat[0]
    else:
        return rdat

if __name__ == "__main__":
    main()
